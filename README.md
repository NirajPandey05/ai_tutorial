# ğŸ¤– AI Engineering Tutorial

[![Python 3.11+](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![FastAPI](https://img.shields.io/badge/FastAPI-0.109+-green.svg)](https://fastapi.tiangolo.com)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

An interactive, comprehensive tutorial website for learning AI Engineering - from LLM fundamentals to production multi-agent systems. Built with FastAPI, featuring hands-on labs, progress tracking, and support for multiple LLM providers.

## âœ¨ Features

### ğŸ“š Comprehensive Curriculum
- **LLM Fundamentals** - Tokens, prompts, parameters, models
- **Advanced LLM Concepts** - Attention mechanisms, architectures, multimodal
- **Embeddings & Vectors** - Vector databases, semantic search, similarity
- **RAG (Retrieval-Augmented Generation)** - Document loading, chunking, retrieval strategies
- **AI Agents** - ReAct, tool use, planning, memory
- **MCP (Model Context Protocol)** - Building MCP servers and integrations
- **Multi-Agent Systems** - Orchestration, collaboration, patterns
- **Fine-tuning** - LoRA, dataset preparation, training workflows
- **Self-Hosting** - Ollama, vLLM, Docker deployments
- **Advanced Topics** - Production architecture, security, evaluation

### ğŸ§ª Hands-on Learning
- **Interactive Labs** - Code directly in the browser
- **Quizzes** - Test your understanding
- **Real API Calls** - Use actual LLM APIs with your own keys
- **Progress Tracking** - Track completion, streaks, achievements

### ğŸ”‘ Bring Your Own Keys
Use any combination of providers:
- **OpenAI** - GPT-5.2, GPT-4o, o3 series
- **Anthropic** - Claude 4, Claude 3.5 Sonnet
- **Google** - Gemini 3 Pro, Gemini 2.5
- **xAI** - Grok 4, Grok 3
- **Local** - Ollama (llama, mistral, phi)

### ğŸ¯ Structured Learning Paths

| Path | Duration | Level | Focus |
|------|----------|-------|-------|
| ğŸš€ Quick Start | 2 hours | Beginner | Get started with LLMs fast |
| ğŸ“š RAG Engineer | 8 hours | Intermediate | Build knowledge-based apps |
| ğŸ¤– Agent Developer | 12 hours | Intermediate | Create autonomous agents |
| ğŸ“ Complete AI Engineer | 50+ hours | All Levels | Master everything |

## ğŸš€ Quick Start

### Prerequisites

- **Python 3.11+** ([Download](https://www.python.org/downloads/))
- **UV** package manager ([Install](https://github.com/astral-sh/uv))
- **Git** ([Download](https://git-scm.com/downloads))

### Installation

```bash
# Clone the repository
git clone https://github.com/yourusername/ai-tutorial.git
cd ai-tutorial

# Install dependencies with UV
uv sync

# Copy environment template
cp .env.example .env

# Start the development server
uv run uvicorn src.ai_tutorial.main:app --reload --port 8080
```

Open **http://localhost:8080** in your browser ğŸ‰

### Configure API Keys

1. Navigate to **Settings** (âš™ï¸) in the sidebar
2. Add API keys for providers you want to use
3. Keys are stored **locally in your browser** (never sent to servers)

## ğŸ“ Project Structure

```
ai-tutorial/
â”œâ”€â”€ src/ai_tutorial/           # Application source code
â”‚   â”œâ”€â”€ main.py               # FastAPI entry point
â”‚   â”œâ”€â”€ config.py             # Configuration management
â”‚   â”œâ”€â”€ content/              # Content registry & models
â”‚   â”‚   â”œâ”€â”€ registry.py       # Module/section/page definitions
â”‚   â”‚   â”œâ”€â”€ models.py         # Data models
â”‚   â”‚   â””â”€â”€ renderer.py       # Markdown rendering
â”‚   â”œâ”€â”€ providers/            # LLM provider adapters
â”‚   â”‚   â”œâ”€â”€ base.py          # Abstract base class
â”‚   â”‚   â”œâ”€â”€ openai_provider.py
â”‚   â”‚   â”œâ”€â”€ anthropic_provider.py
â”‚   â”‚   â”œâ”€â”€ google_provider.py
â”‚   â”‚   â””â”€â”€ xai_provider.py
â”‚   â””â”€â”€ routers/              # API routes
â”‚       â””â”€â”€ pages.py          # Page rendering routes
â”œâ”€â”€ content/                   # Markdown content files
â”‚   â”œâ”€â”€ llm-fundamentals/
â”‚   â”œâ”€â”€ rag/
â”‚   â”œâ”€â”€ agents/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ static/                    # Static assets
â”‚   â”œâ”€â”€ css/styles.css
â”‚   â””â”€â”€ js/
â”‚       â”œâ”€â”€ main.js           # Core functionality
â”‚       â””â”€â”€ progress-tracker.js
â”œâ”€â”€ templates/                 # Jinja2 templates
â”‚   â”œâ”€â”€ base.html
â”‚   â”œâ”€â”€ content/              # Content templates
â”‚   â””â”€â”€ pages/                # Static pages
â”œâ”€â”€ tests/                     # Test suite
â”‚   â”œâ”€â”€ test_providers.py
â”‚   â”œâ”€â”€ test_content_registry.py
â”‚   â””â”€â”€ test_routes.py
â”œâ”€â”€ pyproject.toml            # Project configuration
â””â”€â”€ README.md
```

## ğŸ”§ Development

### Running Tests

```bash
# Run all tests
uv run pytest

# Run with coverage
uv run pytest --cov=src/ai_tutorial

# Run specific test file
uv run pytest tests/test_routes.py -v
```

### Code Quality

```bash
# Format code
uv run black src/

# Lint code
uv run ruff check src/

# Type checking (optional)
uv run mypy src/
```

### Local Development

```bash
# Start with auto-reload
uv run uvicorn src.ai_tutorial.main:app --reload --port 8080

# Run with debug logging
LOG_LEVEL=debug uv run uvicorn src.ai_tutorial.main:app --reload
```

## ğŸ³ Docker Deployment

### Build and Run

```bash
# Build the image
docker build -t ai-tutorial .

# Run the container
docker run -p 8080:8080 ai-tutorial
```

### Docker Compose with Ollama

```bash
# Start all services (includes Ollama for local models)
docker-compose up -d

# View logs
docker-compose logs -f
```

## â˜ï¸ Production Deployment

### Deploy to Fly.io (Recommended)

**Fastest way to deploy - takes ~5 minutes:**

```bash
# Install Flyctl
# Windows:
iwr https://fly.io/install.ps1 -useb | iex

# macOS/Linux:
curl -L https://fly.io/install.sh | sh

# Authenticate
flyctl auth login

# Setup and deploy (Windows)
pwsh scripts/deploy-flyio.ps1 setup
pwsh scripts/deploy-flyio.ps1 deploy

# Setup and deploy (macOS/Linux)
bash scripts/deploy-flyio.sh setup
bash scripts/deploy-flyio.sh deploy
```

**Cost:** ~$5-15/month with auto-scaling to zero when idle.

ğŸ“š **Full guide:** [QUICKSTART_FLYIO.md](QUICKSTART_FLYIO.md) | [DEPLOYMENT.md](docs/DEPLOYMENT.md)

### Other Platforms

The project includes Docker support and can be deployed to:
- **Railway.app** - One-click from GitHub
- **Render.com** - $7/month web service tier
- **Google Cloud Run** - Serverless, pay-per-request
- **AWS Fargate** - Production scale
- **Azure Container Instances** - Enterprise-ready

See [docs/DEPLOYMENT.md](docs/DEPLOYMENT.md) for platform-specific guides.

## ğŸ“– API Documentation

When running, API documentation is available at:
- **Swagger UI**: http://localhost:8080/docs
- **ReDoc**: http://localhost:8080/redoc

### Key Endpoints

| Endpoint | Description |
|----------|-------------|
| `GET /` | Home page |
| `GET /learn/{module}` | Module overview |
| `GET /learn/{module}/{section}/{page}` | Content page |
| `GET /path/{path_id}` | Learning path detail |
| `GET /api/path/{path_id}/content` | Path content JSON |
| `GET /settings` | API key configuration |

## ğŸ¤ Contributing

We welcome contributions! Here's how to get started:

1. **Fork** the repository
2. **Create** a feature branch (`git checkout -b feature/amazing-feature`)
3. **Commit** your changes (`git commit -m 'Add amazing feature'`)
4. **Push** to the branch (`git push origin feature/amazing-feature`)
5. **Open** a Pull Request

### Guidelines

- Follow existing code style (Black + Ruff)
- Add tests for new functionality
- Update documentation as needed
- Keep PRs focused and atomic

## ğŸ”‘ API Key Requirements

| Provider | Required For | Get Keys |
|----------|-------------|----------|
| OpenAI | GPT models, embeddings | [platform.openai.com](https://platform.openai.com) |
| Anthropic | Claude models | [console.anthropic.com](https://console.anthropic.com) |
| Google | Gemini models | [ai.google.dev](https://ai.google.dev) |
| xAI | Grok models | [x.ai](https://x.ai) |

**Note**: All keys are stored in your browser's localStorage and are never transmitted to any server. Labs use client-side API calls only.

## ğŸ“„ License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.

## ğŸ™ Acknowledgments

- Built with [FastAPI](https://fastapi.tiangolo.com/)
- UI components from [Tailwind CSS](https://tailwindcss.com/)
- Reactivity with [Alpine.js](https://alpinejs.dev/)
- Icons from [Heroicons](https://heroicons.com/)

---

**Happy Learning!** ğŸš€

If you find this project helpful, please consider giving it a â­ on GitHub!
